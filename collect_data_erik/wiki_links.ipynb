{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deutscher bundestag\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "link = 'https://de.wikipedia.org/wiki/Liste_der_Mitglieder_des_Deutschen_Bundestages_(20._Wahlperiode)'\n",
    "html = requests.get(link).text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "links = []\n",
    "name = []\n",
    "tabel = soup.find('table','wikitable sortable tabelle-kopf-fixiert')\n",
    "for row in tabel.find_all('tr'):\n",
    "    cells = row.find_all('td')\n",
    "    if len(cells) >3:\n",
    "        links.append(cells[1].find('a')['href'])\n",
    "        name.append(cells[1].find('a').text)\n",
    "        #print(cells[1].find('a')['href'])\n",
    "links_df = pd.DataFrame({'Name':name, 'link':links})\n",
    "df = pd.read_html(link)[2]\n",
    "df = df.merge(links_df)\n",
    "df.to_csv('data/colect links/geram_20.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://de.wikipedia.org/wiki/Liste_der_Mitglieder_des_Deutschen_Bundestages_(19._Wahlperiode)'\n",
    "html = requests.get(link).text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "links = []\n",
    "name = []\n",
    "tabel = soup.find('table','wikitable sortable')\n",
    "for row in tabel.find_all('tr'):\n",
    "    cells = row.find_all('td')\n",
    "    if len(cells) >3:\n",
    "        links.append(cells[1].find('a')['href'])\n",
    "        name.append(cells[1].find('a').text)\n",
    "links_df = pd.DataFrame({'Name':name, 'link':links})\n",
    "df = pd.read_html(link)[3]\n",
    "df = df.merge(links_df)\n",
    "df.to_csv('data/colect links/geram_19.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://de.wikipedia.org/wiki/Liste_der_Mitglieder_des_Deutschen_Bundestages_(18._Wahlperiode)'\n",
    "html = requests.get(link).text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "links = []\n",
    "name = []\n",
    "tabel = soup.find('table','wikitable zebra sortable')\n",
    "for row in tabel.find_all('tr'):\n",
    "    cells = row.find_all('td')\n",
    "    if len(cells) >3:\n",
    "        links.append(cells[0].find('a')['href'])\n",
    "        name.append(cells[0].find('a').text)\n",
    "links_df = pd.DataFrame({'Name':name, 'link':links})\n",
    "links_df\n",
    "df = pd.read_html(link)[1]\n",
    "df = df.rename({'Mitglied des Bundestages':'Name'},axis=1)\n",
    "df = df.merge(links_df)\n",
    "df.to_csv('data/colect links/geram_18.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## austrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://de.wikipedia.org/wiki/Liste_der_Abgeordneten_zum_%C3%96sterreichischen_Nationalrat_(XXVIII._Gesetzgebungsperiode)'\n",
    "html = requests.get(link).text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "links = []\n",
    "name = []\n",
    "tabel = soup.find('table')\n",
    "for row in tabel.find_all('tr'):\n",
    "    cells = row.find_all('td')\n",
    "    if len(cells) >3:\n",
    "        links.append(cells[0].find('a')['href'])\n",
    "        name.append(cells[0].find('a').text)\n",
    "links_df = pd.DataFrame({'Name':name, 'link':links})\n",
    "links_df\n",
    "df = pd.read_html(link)[0]\n",
    "df = df.merge(links_df)\n",
    "df.to_csv('data/colect links/austrian_28.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://de.wikipedia.org/wiki/Liste_der_Abgeordneten_zum_%C3%96sterreichischen_Nationalrat_(XXVII._Gesetzgebungsperiode)'\n",
    "html = requests.get(link).text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "links = []\n",
    "name = []\n",
    "tabel = soup.find('table')\n",
    "for row in tabel.find_all('tr'):\n",
    "    cells = row.find_all('td')\n",
    "    if len(cells) >3:\n",
    "        links.append(cells[0].find('a')['href'])\n",
    "        name.append(cells[0].find('a').text)\n",
    "links_df = pd.DataFrame({'Name':name, 'link':links})\n",
    "links_df\n",
    "df = pd.read_html(link)[0]\n",
    "df = df.merge(links_df)\n",
    "df\n",
    "df.to_csv('data/colect links/austrian_27.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://de.wikipedia.org/wiki/Liste_der_Abgeordneten_zum_%C3%96sterreichischen_Nationalrat_(XXVI._Gesetzgebungsperiode)'\n",
    "html = requests.get(link).text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "links = []\n",
    "name = []\n",
    "tabel = soup.find('table')\n",
    "for row in tabel.find_all('tr'):\n",
    "    cells = row.find_all('td')\n",
    "    if len(cells) >3:\n",
    "        links.append(cells[0].find('a')['href'])\n",
    "        name.append(cells[0].find('a').text)\n",
    "links_df = pd.DataFrame({'Name':name, 'link':links})\n",
    "links_df\n",
    "df = pd.read_html(link)[0]\n",
    "df = df.merge(links_df)\n",
    "df\n",
    "df.to_csv('data/colect links/austrian_26.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://de.wikipedia.org/wiki/Liste_der_Abgeordneten_zum_%C3%96sterreichischen_Nationalrat_(XXV._Gesetzgebungsperiode)'\n",
    "html = requests.get(link).text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "links = []\n",
    "name = []\n",
    "tabel = soup.find('table')\n",
    "for row in tabel.find_all('tr'):\n",
    "    cells = row.find_all('td')\n",
    "    if len(cells) >3:\n",
    "        links.append(cells[0].find('a')['href'])\n",
    "        name.append(cells[0].find('a').text)\n",
    "links_df = pd.DataFrame({'Name':name, 'link':links})\n",
    "links_df\n",
    "df = pd.read_html(link)[0]\n",
    "df = df.merge(links_df)\n",
    "df\n",
    "df.to_csv('data/colect links/austrian_25.csv',index=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
